etlAgent.sources = src1
etlAgent.sinks = sink1

# Describe/configure the source
etlAgent.sources.src1.type = com.gsta.bigdata.etl.flume.SpoolDirectoryCompressSource
etlAgent.sources.src1.spoolDir = /data/huaweidpi/S1ustraming
etlAgent.sources.src1.batchSize=50000
etlAgent.sources.src1.basenameHeader=true
etlAgent.sources.src1.interceptors = dpiInterceptor
etlAgent.sources.src1.interceptors.dpiInterceptor.type=com.gsta.bigdata.etl.flume.DPIInterceptor$Builder
etlAgent.sources.src1.interceptors.dpiInterceptor.delimiter=\\|
#3=MSISDN,13=ECGI,10=SGWIP,22=InputOctets,23=OutputOctets,64=QueryDomainName
etlAgent.sources.src1.interceptors.dpiInterceptor.fields=3,13,10,22,23,64
etlAgent.sources.src1.interceptors.dpiInterceptor.keyField=3
etlAgent.sources.src1.interceptors.dpiInterceptor.headerName=key
etlAgent.sources.src1.interceptors.dpiInterceptor.kafkaPartitions=256

# Describe the sink
etlAgent.sinks.sink1.type = org.apache.flume.sink.kafka.KafkaSink
etlAgent.sinks.sink1.kafka.topic=4GDPI
etlAgent.sinks.sink1.flumeBatchSize=2000
etlAgent.sinks.sink1.kafka.bootstrap.servers=132.122.70.131:9091,132.122.70.131:9092,132.122.70.132:9093,132.122.70.132:9094,132.122.70.133:9095,132.122.70.133:9096,132.122.70.134:9097,132.122.70.134:9098,132.122.70.135:9099,132.122.70.135:9091

# Use a channel which buffers events in memory
etlAgent.channels = ch1
etlAgent.channels.ch1.type = memory
etlAgent.channels.ch1.capacity = 4000000
etlAgent.channels.ch1.transactionCapacity = 2000000
etlAgent.channels.ch1.keep-alive = 60

# Bind the source and sink to the channel
etlAgent.sources.src1.channels = ch1
etlAgent.sinks.sink1.channel = ch1
